{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer,BertModel\n",
    "import numpy as np\n",
    "\n",
    "import data\n",
    "import config\n",
    "import model\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2b35057d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = data.get_loader(train=True)\n",
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "5\n",
      "128\n",
      "torch.Size([128, 2048, 14, 14])\n",
      "Batch 1\n",
      "5\n",
      "34\n",
      "torch.Size([34, 2048, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(trainloader):\n",
    "    print(f\"Batch {i}\")\n",
    "    print(len(batch))\n",
    "    print(len(batch[0]))\n",
    "    print(batch[0].size())\n",
    "    #print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20000 * 3 * 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare toy data\n",
    "\n",
    "# with open(config.QUESTIONS_TEST_FILEPATH, 'r') as fd:\n",
    "#     questions_json = json.load(fd)\n",
    "# with open(config.ANNOTATIONS_VAL_FILEPATH, 'r') as fd:\n",
    "#     answers_json = json.load(fd)\n",
    "\n",
    "# # copy over\n",
    "# questions_json_copy = dict()\n",
    "# questions_json_copy[\"info\"] = questions_json[\"info\"]\n",
    "# questions_json_copy[\"task_type\"] = questions_json[\"task_type\"]\n",
    "# questions_json_copy[\"data_type\"] = questions_json[\"data_type\"]\n",
    "# questions_json_copy[\"license\"] = questions_json[\"license\"]\n",
    "# questions_json_copy[\"data_subtype\"] = questions_json[\"data_subtype\"]\n",
    "# questions_json_copy[\"num_choices\"] = questions_json[\"num_choices\"]\n",
    "# questions_json_copy[\"questions\"] = []\n",
    "# for questions_json_i in questions_json[\"questions\"]:\n",
    "#     if questions_json_i[\"image_id\"] in [30000, 30001, 30002]:\n",
    "#         questions_json_copy[\"questions\"].append(questions_json_i)\n",
    "# # save\n",
    "# with open(\"toy/Questions/Questions_Test_abstract_v002/MultipleChoice_abstract_v002_test2015_questions.json\", 'w') as f:\n",
    "#     json.dump(questions_json_copy, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# # copy over\n",
    "# answers_json_copy = dict()\n",
    "# answers_json_copy[\"info\"] = answers_json[\"info\"]\n",
    "# answers_json_copy[\"data_type\"] = answers_json[\"data_type\"]\n",
    "# answers_json_copy[\"license\"] = answers_json[\"license\"]\n",
    "# answers_json_copy[\"data_subtype\"] = answers_json[\"data_subtype\"]\n",
    "# answers_json_copy[\"annotations\"] = []\n",
    "# for answers_json_i in answers_json[\"annotations\"]:\n",
    "#     if answers_json_i[\"image_id\"] in [20000, 20001, 20002]:\n",
    "#         answers_json_copy[\"annotations\"].append(answers_json_i)\n",
    "\n",
    "# # save\n",
    "# with open(\"toy/Annotations/abstract_v002_val2015_annotations.json\", 'w') as f:\n",
    "#    json.dump(answers_json_copy, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "pretrained_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2054,  3609,  2003,  1996,  6456,  6471,  1029,   102,  2630,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2129,  2003,  1996,  3941,  2015,  2007,  6963,  2170,  1029,\n",
      "           102, 14816,   102,     0],\n",
      "        [  101,  2003,  1996,  2450,  2006,  1996,  6411,  7419,  2317,  2606,\n",
      "          1029,   102,  2748,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4444],\n",
       "        [0.3974],\n",
       "        [0.4640]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    'What color is the ladies pants?', \n",
    "    'How is the equipments with bars called?', \n",
    "    'Is the woman on the couch sporting white hair?'\n",
    "]\n",
    "choices = [\n",
    "    \"blue\", \n",
    "    \"slides\", \n",
    "    \"yes\", \n",
    "]\n",
    "\n",
    "v = torch.rand(3, 2048, 14, 14)\n",
    "\n",
    "# wrapped_input = tokenizer(\n",
    "#     sentences, \n",
    "#     max_length=15, \n",
    "#     add_special_tokens=True, \n",
    "#     truncation=True, \n",
    "#     padding='max_length', \n",
    "#     return_tensors=\"pt\"\n",
    "# )\n",
    "wrapped_input = tokenizer(\n",
    "    text=sentences, \n",
    "    text_pair=choices, \n",
    "    add_special_tokens=True, \n",
    "    truncation=False, \n",
    "    padding=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(wrapped_input)\n",
    "net = model.SimpleNet(pretrained_model)\n",
    "output = net(v, wrapped_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "'input_ids': \n",
    "    tensor([[ 101, 2054, 3609, 2003, 1996, 6456, 6471, 1029,  102,    0,    0,    0, 0,    0,    0],\n",
    "            [ 101, 2129, 2003, 1996, 3941, 2015, 2007, 6963, 2170, 1029,  102,    0,0,    0,    0],\n",
    "            [ 101, 2003, 1996, 2450, 2006, 1996, 6411, 7419, 2317, 2606, 1029,  102,0,    0,    0]]), \n",
    "'token_type_ids': \n",
    "    tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), \n",
    "'attention_mask': \n",
    "    tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9633, 0.5874, 1.6305, 0.8024],\n",
       "          [0.9662, 0.9120, 1.2231, 1.1069],\n",
       "          [1.4864, 1.1959, 1.1099, 0.9549],\n",
       "          [0.8396, 0.8468, 0.9976, 0.9378]],\n",
       "\n",
       "         [[0.9633, 0.5874, 1.6305, 0.8024],\n",
       "          [0.9662, 0.9120, 1.2231, 1.1069],\n",
       "          [1.4864, 1.1959, 1.1099, 0.9549],\n",
       "          [0.8396, 0.8468, 0.9976, 0.9378]],\n",
       "\n",
       "         [[0.9633, 0.5874, 1.6305, 0.8024],\n",
       "          [0.9662, 0.9120, 1.2231, 1.1069],\n",
       "          [1.4864, 1.1959, 1.1099, 0.9549],\n",
       "          [0.8396, 0.8468, 0.9976, 0.9378]]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.rand(1, 3, 4, 4)\n",
    "v.norm(p=2, dim=1, keepdim=True).expand_as(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod(v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.QUESTIONS_TRAIN_FILEPATH, 'r') as fd:\n",
    "    questions_json = json.load(fd)\n",
    "with open(config.ANNOTATIONS_TRAIN_FILEPATH, 'r') as fd:\n",
    "    answers_json = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['filename', 'tracker', 'config', 'weights', 'eval'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_logs = torch.load(\"logs/toy_2024_04_24_22_38_03_1.pth\")\n",
    "toy_logs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_logs[\"eval\"][\"preds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "#a = torch.rand(10).view(-1)\n",
    "#b = torch.rand(10).view(-1)\n",
    "#output = torch.Tensor([1, 0, 1, 0, 1])\n",
    "output = torch.tensor([0, 1, 0, 1, 1])\n",
    "a = torch.tensor([1, 0, 1, 0, 0])\n",
    "agree = (a == output).type(torch.IntTensor)\n",
    "indices_agree = torch.nonzero(a).view(-1) # convert mask to indices\n",
    "pos_agree = agree[indices_agree]     # accuracy for positive examples only\n",
    "pos_acc = pos_agree.float().mean()\n",
    "print(pos_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 6]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "x = list(range(10))\n",
    "x.pop(0)\n",
    "x = random.sample(x, k=2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.3279e-01, 6.3818e-01, 1.0225e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [4.0576e-01, 9.6191e-01, 1.5811e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.3809e+00, 1.6777e+00, 1.9307e+00, ..., 1.4492e+00,\n",
       "         4.3774e-01, 8.9172e-02],\n",
       "        ...,\n",
       "        [2.9370e-01, 6.8848e-01, 2.6367e+00, ..., 4.3384e-01,\n",
       "         1.7847e-01, 3.7744e-01],\n",
       "        [4.3945e-01, 7.2754e-01, 1.5107e+00, ..., 2.9810e-01,\n",
       "         6.5527e-01, 3.3472e-01],\n",
       "        [4.4824e-01, 8.2397e-02, 7.8955e-01, ..., 0.0000e+00,\n",
       "         2.1759e-02, 1.1365e-01]],\n",
       "\n",
       "       [[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 3.0212e-02,\n",
       "         1.9482e-01, 2.3169e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [8.4686e-03, 1.6345e-01, 4.1431e-01, ..., 2.6538e-01,\n",
       "         7.8064e-02, 7.6111e-02],\n",
       "        ...,\n",
       "        [0.0000e+00, 1.0901e-01, 3.6377e-01, ..., 1.8066e-01,\n",
       "         2.9761e-01, 6.5869e-01],\n",
       "        [3.4058e-02, 7.2632e-02, 2.4780e-01, ..., 2.4155e-02,\n",
       "         2.8540e-01, 2.4976e-01],\n",
       "        [8.6164e-04, 2.3755e-01, 4.3408e-01, ..., 0.0000e+00,\n",
       "         2.5208e-02, 0.0000e+00]],\n",
       "\n",
       "       [[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.8955e+00,\n",
       "         3.3027e+00, 2.2012e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.4912e+00,\n",
       "         1.7158e+00, 1.7637e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00,\n",
       "         3.8257e-01, 9.1553e-02],\n",
       "        ...,\n",
       "        [2.5928e-01, 1.8640e-01, 0.0000e+00, ..., 0.0000e+00,\n",
       "         2.1191e-01, 3.0444e-01],\n",
       "        [2.9346e-01, 1.9482e-01, 0.0000e+00, ..., 3.0396e-01,\n",
       "         9.8450e-02, 0.0000e+00],\n",
       "        [3.2715e-01, 6.4746e-01, 0.0000e+00, ..., 1.0126e-01,\n",
       "         0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.0000e+00, 3.5217e-02, 3.7903e-02, ..., 7.1436e-01,\n",
       "         1.0801e+00, 2.6001e-01],\n",
       "        [8.5876e-02, 5.3369e-01, 2.4207e-01, ..., 8.0273e-01,\n",
       "         8.2373e-01, 2.2156e-01],\n",
       "        [1.6403e-02, 1.1993e-01, 0.0000e+00, ..., 1.1729e+00,\n",
       "         5.5371e-01, 3.5547e-01],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 4.4495e-02, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "       [[1.3965e-01, 6.5247e-02, 0.0000e+00, ..., 7.4463e-01,\n",
       "         9.3799e-01, 5.3760e-01],\n",
       "        [3.9600e-01, 3.4912e-02, 0.0000e+00, ..., 1.1426e+00,\n",
       "         6.8213e-01, 1.8347e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 8.8232e-01,\n",
       "         2.7612e-01, 0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 1.4392e-01, 1.2314e+00, ..., 3.0176e-01,\n",
       "         2.2791e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 6.5967e-01, 1.4053e+00, ..., 2.7771e-02,\n",
       "         4.7485e-02, 0.0000e+00],\n",
       "        [8.2855e-03, 9.7266e-01, 1.3564e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "       [[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 4.6631e-01,\n",
       "         1.0771e+00, 8.6328e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 3.5254e-01,\n",
       "         8.1836e-01, 9.1553e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 9.3555e-01,\n",
       "         8.3789e-01, 2.8857e-01],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 8.0200e-02, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00]]], dtype=float16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "features_file = h5py.File(\"resnet_train_embeddings.h5\", 'r')\n",
    "features_file[\"features\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((32, 512))\n",
    "x.view(32, 512, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['y_preds_val', 'y_true_val', 'losses_val', 'overall_accs_val', 'pos_accs_val', 'idx_val', 'q_ids_val', 'losses_train', 'overall_accs_train', 'pos_accs_train'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logs = torch.load(\"logs/toy_2024_04_26_20_20_37_1.pth\", map_location=torch.device('cpu'))\n",
    "attention_logs[\"eval\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9668055 , 0.00073079, 0.00071978, 0.9554876 , 0.0007077 ,\n",
       "       0.55026925, 0.966619  , 0.00072942, 0.00073408, 0.9668766 ,\n",
       "       0.00082607, 0.00083701, 0.7499713 , 0.20152688, 0.00378643,\n",
       "       0.9396422 , 0.00086231, 0.00084142, 0.9273825 , 0.00084333],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[x for x in np.array(attention_logs[\"eval\"][\"y_preds\"]) if x > 0.5152 or x < 0.5147]\n",
    "np.array(attention_logs[\"eval\"][\"y_preds\"][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_preds_val': tensor([0.4949, 0.4946, 0.4949, 0.4947, 0.4953, 0.4950, 0.4943, 0.4954, 0.4940,\n",
       "         0.4977, 0.4975, 0.4980, 0.4985, 0.4976, 0.4993, 0.4984, 0.4973, 0.4982,\n",
       "         0.4998, 0.5001, 0.5004, 0.5001, 0.5003, 0.5001, 0.5016, 0.5009, 0.5006]),\n",
       " 'y_true_val': tensor([1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 1., 0., 0.]),\n",
       " 'losses_val': [0.4620986580848694],\n",
       " 'overall_accs_val': [0.5185185074806213],\n",
       " 'pos_accs_val': [0.2222222238779068],\n",
       " 'idx_val': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26]),\n",
       " 'q_ids_val': tensor([200010, 200010, 200010, 200011, 200011, 200011, 200012, 200012, 200012,\n",
       "         200020, 200020, 200020, 200021, 200021, 200021, 200022, 200022, 200022,\n",
       "         200000, 200000, 200000, 200001, 200001, 200001, 200002, 200002, 200002]),\n",
       " 'losses_train': [0.46085718274116516],\n",
       " 'overall_accs_train': [0.48148149251937866],\n",
       " 'pos_accs_train': [0.7777777910232544]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logs[\"eval\"]#[\"overall_accs_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
